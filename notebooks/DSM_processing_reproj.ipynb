{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00296957-fbb7-4820-bd31-26efc83c2757",
   "metadata": {},
   "source": [
    "## This notebook performs the CRS transformation (EPSG:3857+NAVD88) to UTM_13N_G2139_3D during the pdal processing step itself\n",
    "* This takes 5x amount of time than the no-transformation processing, and was not efficient for large tiles\n",
    "* we parallelized the process and broke it into smaller tiles\n",
    "* To avoid EPT streaming errors, we introduced a 20 second delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d18e130-71cc-478a-8608-73bc386d6ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# Given an area of interest, we want to query and download available USGS 3DEP data. The data should conform to the bounds and crs of the input shape. Options are provided to filter out noise, and generate DTM/DSM, and saving the associated point cloud. We also provide an option to filter out LIDAR returns that exceed a user specified percentile threshold.\n",
    "\n",
    "# %%\n",
    "# PDAL imports\n",
    "import pdal\n",
    "\n",
    "# rasterio imports\n",
    "import rasterio\n",
    "from rasterio.warp import transform_bounds\n",
    "from rasterio import warp\n",
    "from rasterio.merge import merge\n",
    "\n",
    "# GIS imports\n",
    "from pyproj import CRS\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "# Dataframe imports\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# Misc imports\n",
    "import json\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf825e6-28a9-4a88-9180-e2282d1c3e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def return_readers(input_aoi, src_crs, pointcloud_resolution = 1, n_rows = 5, n_cols=5, buffer_value=0):\n",
    "    \"\"\"\n",
    "    This method takes a raster file and finds overlapping 3DEP data. It then returns a series of readers\n",
    "    corresponding to non overlapping areas that can be used as part of further PDAL processing pipelines\n",
    "    The method also returns the CRS specified i\n",
    "    \"\"\"\n",
    "    xmin, ymin, xmax, ymax = input_aoi.bounds\n",
    "    x_step = (xmax - xmin) / n_cols\n",
    "    y_step = (ymax - ymin) / n_rows\n",
    "\n",
    "    dst_crs = CRS.from_epsg(4326)\n",
    "\n",
    "    readers = []\n",
    "    pointcloud_input_crs = []\n",
    "\n",
    "    for i in range(int(n_cols)):\n",
    "        for j in range(int(n_rows)):\n",
    "            aoi = Polygon.from_bounds(xmin+i*x_step, ymin+j*y_step, xmin+(i+1)*x_step, ymin+(j+1)*y_step)\n",
    "\n",
    "            src_bounds_transformed = transform_bounds(src_crs, dst_crs, *aoi.bounds)\n",
    "            aoi_4326 = Polygon.from_bounds(*src_bounds_transformed)\n",
    "\n",
    "            src_bounds_transformed_3857 = transform_bounds(src_crs, CRS.from_epsg(3857), *aoi.bounds)\n",
    "            aoi_3857 = Polygon.from_bounds(*src_bounds_transformed_3857)\n",
    "           # print(aoi.bounds, src_bounds_transformed_3857)\n",
    "            if buffer_value:\n",
    "                aoi_3857.buffer(buffer_value)\n",
    "\n",
    "            gdf = gpd.read_file('https://raw.githubusercontent.com/hobuinc/usgs-lidar/master/boundaries/resources.geojson').set_crs(4326) \n",
    "            # in the eventuality that the above URL breaks, we store a local copy\n",
    "            # gdf = gpd.read_file('../data/shapefiles/resources.geojson').set_crs(4326)\n",
    "\n",
    "            for _, row in gdf.iterrows():\n",
    "                if row.geometry.intersects(aoi_4326):\n",
    "                    usgs_dataset_name = row['name']\n",
    "                    break\n",
    "\n",
    "            #print(\"Dataset being used: \", usgs_dataset_name)\n",
    "            url = f\"https://s3-us-west-2.amazonaws.com/usgs-lidar-public/{usgs_dataset_name}/ept.json\"\n",
    "            reader = {\n",
    "            \"type\": \"readers.ept\",\n",
    "            \"filename\": url,\n",
    "            \"resolution\": pointcloud_resolution,\n",
    "            \"polygon\": str(aoi_3857.wkt),\n",
    "            }\n",
    "            \n",
    "            # SRS associated with the 3DEP dataset\n",
    "            response = requests.get(url)\n",
    "            data = response.json()\n",
    "            # srs_wkt = data['srs']['wkt']\n",
    "            with open(\"SRS_CRS.wkt\", 'r') as f:\n",
    "                srs_wkt = f.read()\n",
    "            \n",
    "            pointcloud_input_crs.append(CRS.from_wkt(srs_wkt))\n",
    "            # print(\"SRS CRS: \", srs_wkt)\n",
    "            readers.append(reader)\n",
    "\n",
    "    return readers, pointcloud_input_crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cdc452-680f-4593-b990-3d3e48f039c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# function that returns a PDAL pipeline to create a pointcloud based on user flags\n",
    "def create_pdal_pipeline(filter_low_noise=True, filter_high_noise=True, \n",
    "                         filter_road=True, reset_classes=False, reclassify_ground=False,\n",
    "                         return_only_ground=False, percentile_filter=True, percentile_threshold=0.95,\n",
    "                         group_filter=None, reproject=True, save_pointcloud=False, \n",
    "                         pointcloud_file = 'pointcloud', input_crs=None,\n",
    "                         output_crs=None, output_type='laz'):\n",
    "    \n",
    "    assert abs(percentile_threshold) <= 1, \"Percentile threshold must be in range [0, 1]\"\n",
    "    assert output_type in ['las', 'laz'], \"Output type must be either 'las' or 'laz'\"\n",
    "    assert output_crs is not None, \"Argument 'output_crs' must be explicitly specified!\"\n",
    "\n",
    "    stage_filter_low_noise = {\n",
    "        \"type\":\"filters.range\",\n",
    "        \"limits\":\"Classification![7:7]\"\n",
    "    }\n",
    "    stage_filter_high_noise = {\n",
    "        \"type\":\"filters.range\",\n",
    "        \"limits\":\"Classification![18:18]\"\n",
    "    }\n",
    "    stage_filter_road = {\n",
    "        \"type\":\"filters.range\",\n",
    "        \"limits\":\"Classification![11:11]\"\n",
    "    }\n",
    "    stage_reset_classes = {\n",
    "        \"type\":\"filters.assign\",\n",
    "        \"value\":\"Classification = 0\"\n",
    "    }\n",
    "    stage_reclassify_ground = {\n",
    "        \"type\":\"filters.smrf\",\n",
    "        # added from pdal smrf documentation, in turn from Pingel, 2013\n",
    "        \"scalar\":1.2,\n",
    "        \"slope\":0.2,\n",
    "        \"threshold\":0.45,\n",
    "        \"window\":8.0\n",
    "    }\n",
    "    stage_group_filter = {\n",
    "        \"type\":\"filters.returns\",\n",
    "        \"groups\":group_filter\n",
    "    }\n",
    "    stage_percentile_filter =  {\n",
    "        \"type\":\"filters.python\",\n",
    "        \"script\":\"filter_percentile.py\",\n",
    "        \"pdalargs\": {\"percentile_threshold\":percentile_threshold},\n",
    "        \"function\":\"filter_percentile\",\n",
    "        \"module\":\"anything\"\n",
    "    }\n",
    "    stage_return_ground = {\n",
    "        \"type\":\"filters.range\",\n",
    "        \"limits\":\"Classification[2:2]\"\n",
    "    }\n",
    "\n",
    "    stage_reprojection = {\n",
    "        \"type\":\"filters.reprojection\",\n",
    "        \"out_srs\":str(output_crs)\n",
    "    }\n",
    "    if input_crs is not None:\n",
    "        stage_reprojection[\"in_srs\"] = str(input_crs)\n",
    "    \n",
    "    stage_save_pointcloud_las = {\n",
    "        \"type\": \"writers.las\",\n",
    "        \"filename\": f\"{pointcloud_file}.las\"\n",
    "    }\n",
    "    stage_save_pointcloud_laz = {\n",
    "        \"type\": \"writers.las\",\n",
    "        \"compression\": \"true\",\n",
    "        \"minor_version\": \"2\",\n",
    "        \"dataformat_id\": \"0\",\n",
    "        \"filename\": f\"{pointcloud_file}.laz\"\n",
    "    }\n",
    "\n",
    "    # Build pipeline\n",
    "    pipeline = []\n",
    "\n",
    "    # resetting the original classifications resets \n",
    "    # all point classifications to 0 (Unclassified)    \n",
    "    if reset_classes:\n",
    "        pipeline.append(stage_reset_classes)\n",
    "        if reclassify_ground:\n",
    "            pipeline.append(stage_reclassify_ground)\n",
    "    else:\n",
    "        # we apply the percentile filter first as it \n",
    "        # classifies detected outliers as 'high noise'\n",
    "        if group_filter is not None:\n",
    "            pipeline.append(stage_group_filter)\n",
    "        if percentile_filter:\n",
    "            pipeline.append(stage_percentile_filter)\n",
    "        if filter_low_noise:\n",
    "            pipeline.append(stage_filter_low_noise)\n",
    "        if percentile_filter or filter_high_noise:\n",
    "            pipeline.append(stage_filter_high_noise)\n",
    "        if filter_road:\n",
    "            pipeline.append(stage_filter_road)\n",
    "\n",
    "    # For creating DTMs, we want to process only ground returns\n",
    "    if return_only_ground:\n",
    "        pipeline.append(stage_return_ground)\n",
    "    \n",
    "    if reproject:\n",
    "        pipeline.append(stage_reprojection)\n",
    "    \n",
    "    # the pipeline can save the pointclouds to a separate file if needed\n",
    "    if save_pointcloud:\n",
    "        if output_type == 'laz':\n",
    "            pipeline.append(stage_save_pointcloud_laz)\n",
    "        else:\n",
    "            pipeline.append(stage_save_pointcloud_las)\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "# %%\n",
    "# function that returns a PDAL pipeline to create a DEM based on user flags\n",
    "def create_dem_stage(dem_filename='dem_output.tif', pointcloud_resolution=1.,\n",
    "                        gridmethod='idw', dimension='Z'):\n",
    "    dem_stage = {\n",
    "            \"type\":\"writers.gdal\",\n",
    "            \"filename\":dem_filename,\n",
    "            \"gdaldriver\":'GTiff',\n",
    "            \"nodata\":-9999,\n",
    "            \"output_type\":gridmethod,\n",
    "            \"resolution\":float(pointcloud_resolution),\n",
    "            \"gdalopts\":\"COMPRESS=LZW,TILED=YES,blockxsize=256,blockysize=256,COPY_SRC_OVERVIEWS=YES\"\n",
    "    }\n",
    "\n",
    "    if dimension == 'Z':\n",
    "        dem_stage.update({\n",
    "            'dimension': 'Z',\n",
    "            'where': 'Z>0'\n",
    "        })\n",
    "    else:\n",
    "        dem_stage.update({\n",
    "            'dimension':dimension\n",
    "        })\n",
    "    \n",
    "    return [dem_stage]\n",
    "\n",
    "# %%\n",
    "# bounds for which pointcloud is created\n",
    "gdf = gpd.read_file('processing_extent.geojson')\n",
    "xmin, ymin, xmax, ymax = gdf.iloc[0].geometry.bounds\n",
    "\n",
    "input_aoi = Polygon.from_bounds(xmin, ymin, xmax, ymax)\n",
    "input_crs = gdf.crs.to_wkt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa8dd20-cec8-4a71-8330-62cee4bef3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    " # specify the input CRS of EPT point clouds\n",
    "with open('SRS_CRS.wkt', 'r') as f:\n",
    "    INPUT_PC_CRS = ' '.join(f.read().replace('\\n', '').split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49902fc2-427f-468b-a3fb-3e73c7adca22",
   "metadata": {},
   "outputs": [],
   "source": [
    " # specify the output CRS of DEMs\n",
    "with open('UTM_13N_WGS84_G2139_3D.wkt', 'r') as f:\n",
    "    OUTPUT_CRS = ' '.join(f.read().replace('\\n', '').split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9550ae3-cd19-4e1f-b5fb-56cc9f0b5477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The method returns pointcloud readers, as well as the pointcloud file CRS as a WKT string\n",
    "# Specfying a buffer_value > 0 will generate overlapping DEM tiles, resulting in a seamless\n",
    "# final mosaicked DEM\n",
    "readers, POINTCLOUD_CRS = return_readers(input_aoi, input_crs, \n",
    "pointcloud_resolution = 1, n_rows=20, n_cols=20, buffer_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823acae6-5a8a-4bdc-b4be-5f9e2d8d20b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pointcloud processing parameters \n",
    "FILTER_LOW_NOISE = True\n",
    "FILTER_HIGH_NOISE = True\n",
    "FILTER_ROAD = False\n",
    "RETURN_ONLY_GROUND = False # Set true for DTM\n",
    "RESET_CLASSES = False\n",
    "RECLASSIFY_GROUND = False\n",
    "PERCENTILE_FILTER = False # Set to True to apply percentile based filtering of Z values\n",
    "PERCENTILE_THRESHOLD = 0.95 # Percentile value to filter out noisy Z returns\n",
    "\n",
    "# \"first,only\" will return top of canopy, \"last,only\" will return lowest return\n",
    "# set to None to use default values\n",
    "GROUP_FILTER=\"first,only\"\n",
    "\n",
    "REPROJECT = True\n",
    "SAVE_POINTCLOUD=False\n",
    "DEM_RESOLUTION = 1\n",
    "OUTPUT_TYPE='laz'\n",
    "GRID_METHOD='idw'\n",
    "DIMENSION='Z' # can be set to options accepted by writers.gdal. Set to 'intensity' to return intensity rasters\n",
    "\n",
    "output_path = Path('tmp_dem_reproj/')\n",
    "output_path.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Number of readers: {len(readers)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e1ea10-b9c5-4983-971c-34ea2bad2564",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import threading\n",
    "import time\n",
    "import random\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af88671e-e35f-426b-8eb4-9b6a19b8f371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(lock):\n",
    "    global starting\n",
    "    starting = lock\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66837506-e603-434b-ad8d-5388627b8e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_pdal_execute(reader_counter_tuple):\n",
    "    starting.acquire() # no other process can get it until it is released\n",
    "    threading.Timer(20, starting.release).start() # release in 20 second\n",
    "    reader,i = reader_counter_tuple\n",
    "    dem_file = output_path / f'dem_tile_aoi_{str(i).zfill(4)}.tif'\n",
    "    if os.path.exists(dem_file):\n",
    "        return 0\n",
    "    else:\n",
    "        pipeline = {'pipeline':[reader]}\n",
    "        pdal_pipeline = create_pdal_pipeline(\n",
    "            filter_low_noise=FILTER_LOW_NOISE,\n",
    "            filter_high_noise=FILTER_HIGH_NOISE,\n",
    "            filter_road=FILTER_ROAD,\n",
    "            reset_classes=RESET_CLASSES, reclassify_ground=RECLASSIFY_GROUND,\n",
    "            return_only_ground=RETURN_ONLY_GROUND, \n",
    "            percentile_filter=PERCENTILE_FILTER, percentile_threshold=PERCENTILE_THRESHOLD,\n",
    "            group_filter=GROUP_FILTER,\n",
    "            reproject=REPROJECT,\n",
    "            save_pointcloud=SAVE_POINTCLOUD, \n",
    "            pointcloud_file='pointcloud', input_crs = INPUT_PC_CRS,\n",
    "            output_crs=OUTPUT_CRS, output_type=OUTPUT_TYPE\n",
    "        )\n",
    "        dem_stage = create_dem_stage(dem_filename=str(dem_file), \n",
    "                                        pointcloud_resolution=DEM_RESOLUTION, \n",
    "                                        gridmethod=GRID_METHOD, dimension=DIMENSION)\n",
    "    \n",
    "        # apply interpolation to fill gaps when generating DSM/DTM\n",
    "        dem_stage[0]['window_size'] = 4\n",
    "        \n",
    "        pipeline['pipeline'] += pdal_pipeline\n",
    "        pipeline['pipeline'] += dem_stage\n",
    "        pipeline = pdal.Pipeline(json.dumps(pipeline))\n",
    "        pipeline.execute()\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9777b99b-50ca-4168-8f08-6400eb043901",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = []\n",
    "for i, reader in enumerate(readers):\n",
    "    tuple_input = (reader,i)\n",
    "    tasks.append(tuple_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4babf2ed-93d6-472f-bc3d-8acbc5d0dd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "readers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed56ec75-adda-4f50-aa02-ea24eb64ecf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0426051-105d-4e9f-8a38-8a7ad6f689d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_imap_multiprocessing(func, argument_list, num_processes):\n",
    "\n",
    "    pool = Pool(processes=num_processes,initializer=init,initargs=[multiprocessing.Lock()])\n",
    "\n",
    "    result_list_tqdm = []\n",
    "    for result in tqdm(pool.imap(func=func, iterable=argument_list), total=len(argument_list)):\n",
    "        result_list_tqdm.append(result)\n",
    "\n",
    "    return result_list_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee35981-4f2e-4698-af97-1b8ef17dec21",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_imap_multiprocessing(parallel_pdal_execute,tasks,num_processes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ae08d2-842e-42b3-a25d-cead8f1a9b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdalbuildvrt dem_mos_utm13N_G2139.vrt tmp_dem_reproj/dem_tile*.tif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb107af-7e55-4a83-8d3f-57df735fbe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to cloud optimised geotiff\n",
    "#cmd \n",
    "!gdal_translate -co TILED=YES -co COMPRESS=LZW -co BIGTIFF=IF_SAFER -co COPY_SRC_OVERVIEWS=YES -co COMPRESS_OVERVIEW=YES -co NUM_THREADS=ALL_CPUS -co PREDICTOR=3 dem_mos_utm13N_G2139.vrt dem_mos_utm13N_G2139.tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b79366-ce1d-428e-a4f8-b960e70d6532",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls dem_mos_utm13N_G2139.tif -lah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddee3855-305f-46f6-9069-e1f6a694b695",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdaladdo -r gauss dem_mos_utm13N_G2139.tif 2 4 8 16 32 64 128 256 512 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2420b89-8d5f-4c05-8a04-0f0ad4ae9bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls dem_mos_utm13N_G2139.tif -lah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0eb504-9eb7-4520-9e4c-30047fc4289e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
